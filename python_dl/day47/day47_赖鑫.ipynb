{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 1、\t掌握常量张量的初始化，运算，变量的赋值，加减乘除等"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import pandas as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os,sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3. 6.], shape=(2,), dtype=float32)\n",
      "------------------------------\n",
      "tf.Tensor([2. 5.], shape=(2,), dtype=float32)\n",
      "<class 'numpy.ndarray'>\n",
      "------------------------------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[[11. 12. 13.]\n",
      " [14. 15. 16.]], shape=(2, 3), dtype=float32)\n",
      "------------------------------\n",
      "tf.Tensor(\n",
      "[[14. 32.]\n",
      " [32. 77.]], shape=(2, 2), dtype=float32)\n",
      "------------------------------\n",
      "tf.Tensor(\n",
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tf常量的运算\n",
    "t = tf.constant([[1.,2,3],[4,5,6]])\n",
    "print(t[:,2]) # 取第二列元素\n",
    "print('-'*30)\n",
    "print(t[...,1])\n",
    "a = t.numpy()\n",
    "print(type(a))\n",
    "print('-'*30)\n",
    "b = tf.constant(a)\n",
    "print(type(b))\n",
    "print(t+10)\n",
    "print('-'*30)\n",
    "print(t @ tf.transpose(t)) # @表示矩阵乘法\n",
    "print('-'*30)\n",
    "print(tf.square(t))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[10., 20., 30.],\n",
      "       [ 4.,  5.,  6.]], dtype=float32)>\n",
      "------------------------------\n",
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[10., 20., 13.],\n",
      "       [ 4.,  5., 16.]], dtype=float32)>\n",
      "------------------------------\n",
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[ 10.,  20.,  13.],\n",
      "       [  4., 200.,  16.]], dtype=float32)>\n",
      "------------------------------\n",
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[500.,  20.,  13.],\n",
      "       [  4., 200., 600.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# tf变量的运算\n",
    "t = tf.Variable([[1.,2,3],[4,5,6]])\n",
    "t[:1].assign(t[:1]*10) # assign是对变量进行原地的修改，提升了效率\n",
    "print(t)\n",
    "print('-'*30)\n",
    "t[:,2].assign([13,16])\n",
    "print(t)\n",
    "print('-'*30)\n",
    "t[1,1].assign(200)\n",
    "print(t)\n",
    "print('-'*30)\n",
    "t.scatter_nd_update(indices=[[0,0],[1,2]],updates=[500,600])\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2、\t掌握RaggedTensor和SparseTensor的初始化 ，以及与tensor之间的互相转换"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[1.0, 2.0, 3.0], [4.0], [], [6.0, 7.0]]>\n",
      "------------------------------\n",
      "<tf.RaggedTensor [[1.0, 2.0, 3.0], [4.0], [], [6.0, 7.0], [4.0, 5.0, 6.0], [100.0, 200.0],\n",
      " [], []]>\n",
      "------------------------------\n",
      "<tf.RaggedTensor [[1.0, 2.0, 3.0, 4.0, 5.0, 6.0], [4.0, 100.0, 200.0], [], [6.0, 7.0]]>\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n"
     ]
    }
   ],
   "source": [
    "# ragged tensor\n",
    "r1 = tf.ragged.constant([[1.,2,3],[4],[],[6,7]]) # 不规则矩阵\n",
    "r2 = tf.ragged.constant([[4.,5,6],[100,200],[],[]])\n",
    "print(r1)\n",
    "print('-'*30)\n",
    "print(tf.concat([r1,r2],axis=0))\n",
    "print('-'*30)\n",
    "print(tf.concat([r1,r2],axis=1))\n",
    "print(type(r1.to_tensor()))  #ragged tensor --> tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[0 0]\n",
      " [1 1]\n",
      " [2 2]\n",
      " [3 3]], shape=(4, 2), dtype=int64), values=tf.Tensor([4. 5. 6. 7.], shape=(4,), dtype=float32), dense_shape=tf.Tensor([4 4], shape=(2,), dtype=int64))\n",
      "------------------------------\n",
      "tf.Tensor(\n",
      "[[4. 0. 0. 0.]\n",
      " [0. 5. 0. 0.]\n",
      " [0. 0. 6. 0.]\n",
      " [0. 0. 0. 7.]], shape=(4, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# sparse tensor\n",
    "s = tf.SparseTensor(indices=[[0,0],[1,1],[2,2],[3,3]],\n",
    "                    values = [4.,5,6,7],\n",
    "                    dense_shape=[4,4])\n",
    "print(s)\n",
    "t = tf.sparse.to_dense(s)  # sparse --> tensor\n",
    "print('-'*30)\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3、\t掌握自定义损失函数，自定义层"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# 自定义损失函数\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "house_price = fetch_california_housing()\n",
    "x_train,x_test,y_train,y_test = train_test_split(\n",
    "    house_price.data,house_price.target,random_state=11)\n",
    "x_train,x_val,y_train,y_val = train_test_split(\n",
    "    x_train,y_train,random_state=22)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11610, 8)\n",
      "(5160, 8)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stand = StandardScaler()\n",
    "x_train = stand.fit_transform(x_train)\n",
    "x_val = stand.transform(x_val)\n",
    "x_test = stand.transform(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def customize_mse(y_true,y_pred):\n",
    "    loss = tf.reduce_mean(tf.square(y_pred-y_true))\n",
    "    return loss\n",
    "model = keras.models.Sequential(\n",
    "    [layers.Dense(30,activation='relu',input_shape=x_train.shape[1:]),\n",
    "     layers.Dense(1)])\n",
    "model.compile(loss=customize_mse,\n",
    "              metrics=['mean_squared_error'],\n",
    "              optimizer='sgd')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8550 - mean_squared_error: 0.8550 - val_loss: 0.5832 - val_mean_squared_error: 0.5832\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5086 - mean_squared_error: 0.5086 - val_loss: 0.4978 - val_mean_squared_error: 0.4978\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4596 - mean_squared_error: 0.4596 - val_loss: 0.4686 - val_mean_squared_error: 0.4686\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 998us/step - loss: 0.4393 - mean_squared_error: 0.4393 - val_loss: 0.4609 - val_mean_squared_error: 0.4609\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4285 - mean_squared_error: 0.4285 - val_loss: 0.4568 - val_mean_squared_error: 0.4568\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4283 - mean_squared_error: 0.4283 - val_loss: 0.4422 - val_mean_squared_error: 0.4422\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4142 - mean_squared_error: 0.4142 - val_loss: 0.4363 - val_mean_squared_error: 0.4363\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4074 - mean_squared_error: 0.4074 - val_loss: 0.4295 - val_mean_squared_error: 0.4295\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4024 - mean_squared_error: 0.4024 - val_loss: 0.4297 - val_mean_squared_error: 0.4297\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3977 - mean_squared_error: 0.3977 - val_loss: 0.4186 - val_mean_squared_error: 0.4186\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3935 - mean_squared_error: 0.3935 - val_loss: 0.4162 - val_mean_squared_error: 0.4162\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3991 - mean_squared_error: 0.3991 - val_loss: 0.4196 - val_mean_squared_error: 0.4196\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3842 - mean_squared_error: 0.3842 - val_loss: 0.4167 - val_mean_squared_error: 0.4167\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3820 - mean_squared_error: 0.3820 - val_loss: 0.4035 - val_mean_squared_error: 0.4035\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3779 - mean_squared_error: 0.3779 - val_loss: 0.4045 - val_mean_squared_error: 0.4045\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3766 - mean_squared_error: 0.3766 - val_loss: 0.3984 - val_mean_squared_error: 0.3984\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3714 - mean_squared_error: 0.3714 - val_loss: 0.4143 - val_mean_squared_error: 0.4143\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 954us/step - loss: 0.3722 - mean_squared_error: 0.3722 - val_loss: 0.3916 - val_mean_squared_error: 0.3916\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3680 - mean_squared_error: 0.3680 - val_loss: 0.3970 - val_mean_squared_error: 0.3970\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3667 - mean_squared_error: 0.3667 - val_loss: 0.4033 - val_mean_squared_error: 0.4033\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,\n",
    "                    validation_data=(x_val,y_val),\n",
    "                    epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "# 自定义层\n",
    "class CustomizeLayer(keras.layers.Layer):\n",
    "    def __init__(self,units,activation=None,**kwargs):\n",
    "        self.units = units\n",
    "        self.activation=keras.layers.Activation(activation)\n",
    "        super(CustomizeLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        \"\"\"构建层\"\"\"\n",
    "        self.kernel=self.add_weight(name='kernel',\n",
    "                                    shape=(input_shape[1],self.units),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "        self.bias = self.add_weight(name='bias',\n",
    "                                    shape=(self.units),\n",
    "                                    initializer='zeros',\n",
    "                                    trainable=True)\n",
    "        super(CustomizeLayer,self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        \"\"\"前向传播的计算\"\"\"\n",
    "        return self.activation(x @ self.kernel + self.bias)\n",
    "model = keras.models.Sequential(\n",
    "    [CustomizeLayer(30,activation='relu',\n",
    "                    input_shape=x_train.shape[1:]),\n",
    "     CustomizeLayer(1)]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "model.compile(loss=customize_mse,\n",
    "              metrics=['mean_squared_error'],\n",
    "              optimizer='sgd')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.0755 - mean_squared_error: 1.0755 - val_loss: 0.6331 - val_mean_squared_error: 0.6331\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5484 - mean_squared_error: 0.5484 - val_loss: 0.5496 - val_mean_squared_error: 0.5496\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4914 - mean_squared_error: 0.4914 - val_loss: 0.5221 - val_mean_squared_error: 0.5221\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4707 - mean_squared_error: 0.4707 - val_loss: 0.5116 - val_mean_squared_error: 0.5116\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.4603 - mean_squared_error: 0.4603 - val_loss: 0.4934 - val_mean_squared_error: 0.4934\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4521 - mean_squared_error: 0.4521 - val_loss: 0.4799 - val_mean_squared_error: 0.4799\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4446 - mean_squared_error: 0.4446 - val_loss: 0.4815 - val_mean_squared_error: 0.4815\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.4385 - mean_squared_error: 0.4385 - val_loss: 0.4699 - val_mean_squared_error: 0.4699\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4309 - mean_squared_error: 0.4309 - val_loss: 0.4574 - val_mean_squared_error: 0.4574\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4243 - mean_squared_error: 0.4243 - val_loss: 0.4494 - val_mean_squared_error: 0.4494\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4185 - mean_squared_error: 0.4185 - val_loss: 0.4556 - val_mean_squared_error: 0.4556\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4131 - mean_squared_error: 0.4131 - val_loss: 0.4456 - val_mean_squared_error: 0.4456\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.4091 - mean_squared_error: 0.4091 - val_loss: 0.4306 - val_mean_squared_error: 0.4306\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 932us/step - loss: 0.4044 - mean_squared_error: 0.4044 - val_loss: 0.4422 - val_mean_squared_error: 0.4422\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 922us/step - loss: 0.4004 - mean_squared_error: 0.4004 - val_loss: 0.4241 - val_mean_squared_error: 0.4241\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3958 - mean_squared_error: 0.3958 - val_loss: 0.4192 - val_mean_squared_error: 0.4192\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3929 - mean_squared_error: 0.3929 - val_loss: 0.4155 - val_mean_squared_error: 0.4155\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3897 - mean_squared_error: 0.3897 - val_loss: 0.4122 - val_mean_squared_error: 0.4122\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3872 - mean_squared_error: 0.3872 - val_loss: 0.4136 - val_mean_squared_error: 0.4136\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3856 - mean_squared_error: 0.3856 - val_loss: 0.4051 - val_mean_squared_error: 0.4051\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,\n",
    "                    validation_data=(x_val,y_val),\n",
    "                    epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4、\t掌握tf.function的使用"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "tf.Tensor(8.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def cube(x):\n",
    "    \"\"\"python函数\"\"\"\n",
    "    return x**3\n",
    "print(cube(2))\n",
    "print(cube(tf.constant(2.0)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "function"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cube)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.eager.def_function.Function'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "27"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把python函数转换为tensorflow函数\n",
    "tf_cube = tf.function(cube)\n",
    "print(type(tf_cube))\n",
    "tf_cube(3.)\n",
    "tf_cube.python_function(3) # 使用python函数方式调用"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}