{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "* 分类：适用于离散型数据，预测输入数据具体是什么类别\n",
    "* 回归：适用于连续性数据，通过之前的数据预测未来的数据\n",
    "* 有监督：输入的数据有其对应的标签\n",
    "* 无监督：输入的数据没有标签"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import jieba\n",
    "import numpy as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t2.0\n",
      "  (0, 2)\t1.0\n",
      "  (1, 1)\t1.0\n",
      "  (1, 2)\t3.0\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "['bar' 'baz' 'foo']\n",
      "------------------------------\n",
      "[{'bar': 2.0, 'foo': 1.0}, {'baz': 1.0, 'foo': 3.0}]\n",
      "------------------------------\n",
      "  (0, 2)\t4.0\n"
     ]
    }
   ],
   "source": [
    "v = DictVectorizer(sparse=True)\n",
    "d = [{'foo': 1, 'bar': 2},\n",
    "     {'foo':3, 'baz':1}]\n",
    "x = v.fit_transform(d)\n",
    "print(x)\n",
    "print(type(x))  # sparse._csr.csr_matrix  sparse矩阵\n",
    "print(v.get_feature_names_out())  # 输出特征值的名称\n",
    "print('-' * 30)\n",
    "print(v.inverse_transform(x))  # 把特征转换成原来的样子\n",
    "print('-' * 30)\n",
    "print(v.transform({'foo':4, 'unseen_feature': 3}))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   1.   0. 100.]\n",
      " [  1.   0.   0.  90.]\n",
      " [  0.   0.   1.  70.]]\n",
      "------------------------------\n",
      "['city=上海' 'city=成都' 'city=深圳' 'temperature']\n",
      "------------------------------\n",
      "[{'city=成都': 1.0, 'temperature': 100.0}, {'city=上海': 1.0, 'temperature': 90.0}, {'city=深圳': 1.0, 'temperature': 70.0}]\n"
     ]
    }
   ],
   "source": [
    "def dict_vec():\n",
    "    \"\"\"\n",
    "    字典数据特征抽取\n",
    "    把字典数据向量化\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # 实例化DictVectorizer对象\n",
    "    dict1 = DictVectorizer(sparse=False)\n",
    "    # 将字典转换为ont-hot编码的向量\n",
    "    data = dict1.fit_transform([{'city': '成都', 'temperature':100},\n",
    "                                {'city': '上海', 'temperature': 90},\n",
    "                                {'city':'深圳', 'temperature': 70}])\n",
    "    print(data)\n",
    "    print('-' * 30)\n",
    "    print(dict1.get_feature_names_out())\n",
    "    print('-' * 30)\n",
    "    print(dict1.inverse_transform(data))\n",
    "\n",
    "dict_vec()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['day' 'good' 'hope' 'is' 'life' 'like' 'love' 'me' 'python' 'short'\n",
      " 'study' 'too' 'up']\n",
      "------------------------------\n",
      "  (0, 4)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 8)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 11)\t1\n",
      "  (2, 1)\t2\n",
      "  (2, 10)\t1\n",
      "  (3, 0)\t2\n",
      "  (3, 12)\t1\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "------------------------------\n",
      "[[0 0 0 1 1 0 1 0 1 1 0 0 0]\n",
      " [0 0 1 0 0 1 0 1 0 0 0 1 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [2 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "------------------------------\n",
      "[array(['life', 'is', 'short', 'love', 'python'], dtype='<U6'), array(['hope', 'like', 'me', 'too'], dtype='<U6'), array(['good', 'study'], dtype='<U6'), array(['day', 'up'], dtype='<U6')]\n"
     ]
    }
   ],
   "source": [
    "def count_vec():\n",
    "    \"\"\"\n",
    "    对文本进行特征值化,\n",
    "    单个汉字单个字母不统计，\n",
    "    因为单个汉字字母没有意义\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 实例化CountVectorizer对象,用于文本特征\n",
    "    text_vec =  CountVectorizer()\n",
    "    res = text_vec.fit_transform([\"life is short, i love python\",\n",
    "                                  \"i hope like me too\",\n",
    "                                  \"good good study\",\n",
    "                                  \"day day up\"])\n",
    "    # 把每个词都给分离开了\n",
    "    print(text_vec.get_feature_names_out())\n",
    "    print('-' * 30)\n",
    "    print(res)\n",
    "    print(type(res))\n",
    "    print('-' * 30)\n",
    "    # 输出向量化之后的矩阵，标记每个词出现的次数\n",
    "    print(res.toarray())\n",
    "    print('-' * 30)\n",
    "    print(text_vec.inverse_transform(res))\n",
    "\n",
    "count_vec()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['人生苦短' '但是我喜欢python' '很强大' '我用python']\n",
      "------------------------------\n",
      "  (0, 0)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 1)\t1\n",
      "------------------------------\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "text = CountVectorizer()\n",
    "data = [\"人生苦短，我用python\",\"C++很强大，但是我喜欢python\"]\n",
    "data = text.fit_transform(data)\n",
    "print(text.get_feature_names_out())\n",
    "print('-' * 30)\n",
    "print(data)\n",
    "print('-' * 30)\n",
    "# 将parse矩阵转换为ndarray\n",
    "print(data.toarray())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "------------------------------\n",
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "('今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天',\n '我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。',\n '如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。')"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cut_word():\n",
    "    \"\"\"\n",
    "    jieba分词\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    con1 = jieba.cut(\"今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天\")\n",
    "\n",
    "    con2 = jieba.cut(\"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。\")\n",
    "\n",
    "    con3 = jieba.cut(\"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。\")\n",
    "\n",
    "    print(type(con1)) # generator\n",
    "    print('-' * 30)\n",
    "    # 将生成器转换为列表类型\n",
    "    content1 = list(con1)\n",
    "    content2 = list(con2)\n",
    "    content3 = list(con3)\n",
    "    # print(content1)\n",
    "    # print(content2)\n",
    "    # print(content3)\n",
    "    # print('-' * 30)\n",
    "    c1 = ' '.join(content1)\n",
    "    c2 = ' '.join(content2)\n",
    "    c3 = ' '.join(content3)\n",
    "\n",
    "    return c1, c2, c3\n",
    "\n",
    "\n",
    "cut_word()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "------------------------------\n",
      "['今天', '很', '残酷', '，', '明天', '更', '残酷', '，', '后天', '很', '美好', '，', '但', '绝对', '大部分', '是', '死', '在', '明天', '晚上', '，', '所以', '每个', '人', '不要', '放弃', '今天']\n",
      "['我们', '看到', '的', '从', '很', '远', '星系', '来', '的', '光是在', '几百万年', '之前', '发出', '的', '，', '这样', '当', '我们', '看到', '宇宙', '时', '，', '我们', '是', '在', '看', '它', '的', '过去', '。']\n",
      "['如果', '只用', '一种', '方式', '了解', '某样', '事物', '，', '你', '就', '不会', '真正', '了解', '它', '。', '了解', '事物', '真正', '含义', '的', '秘密', '取决于', '如何', '将', '其', '与', '我们', '所', '了解', '的', '事物', '相', '联系', '。']\n",
      "------------------------------\n",
      "['一种' '不会' '不要' '之前' '了解' '事物' '今天' '光是在' '几百万年' '发出' '取决于' '只用' '后天' '含义'\n",
      " '大部分' '如何' '如果' '宇宙' '我们' '所以' '放弃' '方式' '明天' '星系' '晚上' '某样' '残酷' '每个'\n",
      " '看到' '真正' '秘密' '绝对' '美好' '联系' '过去' '这样']\n",
      "[[0 0 1 0 0 0 2 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 2 0 1 0 2 1 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 3 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 1 1]\n",
      " [1 1 0 0 4 3 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 2 1 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def chine_vec():\n",
    "    \"\"\"\n",
    "    中文特征化\n",
    "    :return:None\n",
    "    \"\"\"\n",
    "    c1, c2, c3 = cut_word()\n",
    "    cv = CountVectorizer()\n",
    "    data = cv.fit_transform([c1, c2,c3])\n",
    "    print(cv.get_feature_names_out())\n",
    "    print(data.toarray())\n",
    "\n",
    "chine_vec()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "------------------------------\n",
      "<class 'str'>\n",
      "['一种' '不会' '不要' '之前' '了解' '事物' '今天' '光是在' '几百万年' '发出' '取决于' '只用' '后天' '含义'\n",
      " '大部分' '如何' '如果' '宇宙' '我们' '所以' '放弃' '方式' '明天' '星系' '晚上' '某样' '残酷' '每个'\n",
      " '看到' '真正' '秘密' '绝对' '美好' '联系' '过去' '这样']\n",
      "------------------------------\n",
      "  (0, 20)\t0.2182178902359924\n",
      "  (0, 2)\t0.2182178902359924\n",
      "  (0, 27)\t0.2182178902359924\n",
      "  (0, 19)\t0.2182178902359924\n",
      "  (0, 24)\t0.2182178902359924\n",
      "  (0, 14)\t0.2182178902359924\n",
      "  (0, 31)\t0.2182178902359924\n",
      "  (0, 32)\t0.2182178902359924\n",
      "  (0, 12)\t0.2182178902359924\n",
      "  (0, 22)\t0.4364357804719848\n",
      "  (0, 26)\t0.4364357804719848\n",
      "  (0, 6)\t0.4364357804719848\n",
      "  (1, 34)\t0.24108220270067757\n",
      "  (1, 17)\t0.24108220270067757\n",
      "  (1, 35)\t0.24108220270067757\n",
      "  (1, 9)\t0.24108220270067757\n",
      "  (1, 3)\t0.24108220270067757\n",
      "  (1, 8)\t0.24108220270067757\n",
      "  (1, 7)\t0.24108220270067757\n",
      "  (1, 23)\t0.24108220270067757\n",
      "  (1, 28)\t0.48216440540135513\n",
      "  (1, 18)\t0.5500476874707075\n",
      "  (2, 33)\t0.15698297076974738\n",
      "  (2, 15)\t0.15698297076974738\n",
      "  (2, 10)\t0.15698297076974738\n",
      "  (2, 30)\t0.15698297076974738\n",
      "  (2, 13)\t0.15698297076974738\n",
      "  (2, 29)\t0.31396594153949475\n",
      "  (2, 1)\t0.15698297076974738\n",
      "  (2, 5)\t0.47094891230924213\n",
      "  (2, 25)\t0.15698297076974738\n",
      "  (2, 4)\t0.6279318830789895\n",
      "  (2, 21)\t0.15698297076974738\n",
      "  (2, 0)\t0.15698297076974738\n",
      "  (2, 11)\t0.15698297076974738\n",
      "  (2, 16)\t0.15698297076974738\n",
      "  (2, 18)\t0.11938959557761185\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[0.         0.         0.21821789 0.         0.         0.\n",
      "  0.43643578 0.         0.         0.         0.         0.\n",
      "  0.21821789 0.         0.21821789 0.         0.         0.\n",
      "  0.         0.21821789 0.21821789 0.         0.43643578 0.\n",
      "  0.21821789 0.         0.43643578 0.21821789 0.         0.\n",
      "  0.         0.21821789 0.21821789 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.2410822  0.         0.\n",
      "  0.         0.2410822  0.2410822  0.2410822  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.2410822\n",
      "  0.55004769 0.         0.         0.         0.         0.2410822\n",
      "  0.         0.         0.         0.         0.48216441 0.\n",
      "  0.         0.         0.         0.         0.2410822  0.2410822 ]\n",
      " [0.15698297 0.15698297 0.         0.         0.62793188 0.47094891\n",
      "  0.         0.         0.         0.         0.15698297 0.15698297\n",
      "  0.         0.15698297 0.         0.15698297 0.15698297 0.\n",
      "  0.1193896  0.         0.         0.15698297 0.         0.\n",
      "  0.         0.15698297 0.         0.         0.         0.31396594\n",
      "  0.15698297 0.         0.         0.15698297 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def tf_idf_vec():\n",
    "    \"\"\"\n",
    "    计算TF-IDF值：表示改文件的重要程度\n",
    "    TF：表示改词出现的次数\n",
    "    IDF：表示逆文档频率\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 把通过jieba分词之后的字符串用于特征提取\n",
    "    c1, c2,c3 = cut_word()\n",
    "    data = [c1,c2,c3]\n",
    "    # 实例化TfidfVectorizer()对象\n",
    "    tf = TfidfVectorizer()\n",
    "    # 向量化\n",
    "    res = tf.fit_transform(data)\n",
    "    # 输出特征的具体名称\n",
    "    print(tf.get_feature_names_out())\n",
    "    print('-' * 30)\n",
    "    print(res)\n",
    "    print(type(res)) # parse矩阵\n",
    "    # 将parse矩阵转换为ndarray\n",
    "    print(res.toarray())\n",
    "\n",
    "tf_idf_vec()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 特征处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.         0.        ]\n",
      " [0.         1.         1.         0.83333333]\n",
      " [0.5        0.5        0.6        1.        ]]\n",
      "------------------------------\n",
      "[[90, 2, 10, 40], [60, 4, 15, 45], [75, 3, 13, 46]]\n"
     ]
    }
   ],
   "source": [
    "def min_max():\n",
    "    \"\"\"\n",
    "    归一化处理\n",
    "    :return:None\n",
    "    \"\"\"\n",
    "    # X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "    min_max = MinMaxScaler(feature_range=(0,1))\n",
    "    data = [[90,2,10,40],[60,4,15,45],[75,3,13,46]]\n",
    "    res = min_max.fit_transform(data)\n",
    "    print(res)\n",
    "\n",
    "\n",
    "min_max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.06904497 -1.35873244  0.98058068]\n",
      " [-0.26726124  0.33968311  0.39223227]\n",
      " [ 1.33630621  1.01904933 -1.37281295]]\n",
      "------------------------------\n",
      "[2.33333333 3.         1.33333333]\n",
      "[1.55555556 8.66666667 2.88888889]\n",
      "3\n",
      "--------------------------------------------------\n",
      "[[-1.06904497 -1.35873244  0.98058068]\n",
      " [-0.26726124  0.33968311  0.39223227]\n",
      " [ 1.33630621  1.01904933 -1.37281295]]\n",
      "--------------------------------------------------\n",
      "[0. 0. 0.]\n",
      "[1.         1.         1.00000001]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def stand():\n",
    "    \"\"\"\n",
    "    标准化缩放,均值为0，方差为1\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    std = StandardScaler()\n",
    "    data = [[1.,-1.,3.],[2.,4.,2.],[4.,6.,-1.]]\n",
    "    res = std.fit_transform(data)\n",
    "    print(res)\n",
    "    print('-' * 30)\n",
    "    print(std.mean_) # 均值\n",
    "    print(std.var_)  # 方差\n",
    "    print(std.n_samples_seen_)  # 样本数\n",
    "    print('-' * 50)\n",
    "    res1 = std.fit_transform([[-1.06904497, -1.35873244,  0.98058068],\n",
    "                              [-0.26726124,  0.33968311,  0.39223227],\n",
    "                              [ 1.33630621,  1.01904933, -1.37281295]])\n",
    "    print(res1)\n",
    "    print('-' * 50)\n",
    "    print(std.mean_) # 均值=0\n",
    "    print(std.var_)  # 方差=1\n",
    "    print(std.n_samples_seen_)  # 样本数\n",
    "\n",
    "stand()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 缺失值处理"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         2.        ]\n",
      " [3.66666667 3.        ]\n",
      " [7.         6.        ]\n",
      " [3.         2.        ]]\n"
     ]
    }
   ],
   "source": [
    "def imput():\n",
    "    \"\"\"\n",
    "    缺失值的处理\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    im = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    data = [[1,2],[np.nan,3],[7,6],[3,2]]\n",
    "    res = im.fit_transform(data)\n",
    "    print(res)\n",
    "\n",
    "imput()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [4]\n",
      " [1]]\n",
      "------------------------------\n",
      "[False False  True False]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "def drop_var():\n",
    "    \"\"\"\n",
    "    删除低方差特征\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    d_var = VarianceThreshold(threshold=1)\n",
    "    data = [[0,2,0,3],\n",
    "            [0,1,4,3],\n",
    "            [0,1,1,3]]\n",
    "    res = d_var.fit_transform(data)\n",
    "    print(res)\n",
    "    print('-' * 30)\n",
    "    # 查看剩余的特征的列编号\n",
    "    print(d_var.get_support())\n",
    "    print(d_var.get_support(True))\n",
    "\n",
    "drop_var()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.28620952e-15  3.82970843e+00]\n",
      " [ 5.74456265e+00 -1.91485422e+00]\n",
      " [-5.74456265e+00 -1.91485422e+00]]\n"
     ]
    }
   ],
   "source": [
    "def pca():\n",
    "    \"\"\"\n",
    "    进行特征降维\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # n_component选在在0-1之间\n",
    "    pca = PCA(n_components=0.9)\n",
    "    data = [[2,8,4,5],[6,3,0,8],[5,4,9,1]]\n",
    "    res = pca.fit_transform(data)\n",
    "    print(res)\n",
    "\n",
    "pca()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}